{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6DOF processing of the 2018 M7.8 gulf of Alaska earthquake\n",
    "\n",
    "This tutorial will teach you how to process six component seismic data as recorded by collocated translational and rotational seismometers. The data used in this tutorial was recorded at the large ring laser observatory ROMY in Furstenfeldbruck, Germany after the January, 23rd 2018 M7.8 gulf of Alaska earthquake (Occurence Time: 2018-01-23 09:31:40 UTC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pol6C as pr # This is the main module used for 6DOF polarization analysis\n",
    "import numpy as np\n",
    "from obspy import read\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import date2num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by reading in the 6DOF data and apply some basic pre-processing to it using  standard ObsPy functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traN = read(\"BW.ROMY.11.TLN.2018.023\") # Translational North component\n",
    "traE = read(\"BW.ROMY.11.TLE.2018.023\") # Translational East component\n",
    "traZ = read(\"BW.ROMY.11.TLZ.2018.023\") # Translational West component\n",
    "rotN = read(\"BW.ROMY.11.RTN.2018.023\") # Rotational North component\n",
    "rotE = read(\"BW.ROMY.11.RTE.2018.023\") # Rotational East component\n",
    "rotZ = read(\"BW.ROMY.11.RTZ.2018.023\") # Rotational West component\n",
    "\n",
    "data = [traN, traE, traZ, rotN, rotE, rotZ]\n",
    "\n",
    "for stream in data:\n",
    "    stream.detrend('spline', order=5, dspline=100) # Detrend the data\n",
    "    stream.trim(starttime=stream[0].stats.starttime, endtime=stream[0].stats.endtime - 4500) # We cut 4500 seconds from the end of the data to decrease the computational complexity of the analysis\n",
    "    stream.taper(0.2)# Taper the data to avoid artifacts in the S-transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now have a look at our data (Fig. 2 in the accompanying paper). The six time series are already corrected for the instrument response, so that the amplitudes are given in acceleration (in m/s/s) for the translational motions and rotation rate (rad/s) for the rotational motions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6, 1, sharex=True, figsize=(12,12), dpi= 100)\n",
    "\n",
    "for i, stream in enumerate(data):\n",
    "    ax[i].plot(stream[0].times(\"matplotlib\"), stream[0].data, 'k-')\n",
    "    ax[i].xaxis_date()\n",
    "    ax[i].set_title(stream[0].id)\n",
    "fig.autofmt_xdate()\n",
    "ax[-1].set_xlabel('UTC Time: DD HH:MM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the amplitudes of the translational components are on the order of +/- 2e-5 m/s/s, while the amplitudes of the rotational components are on the order of +/- 5e-9 rad/s. When performing polarization analysis, this would lead to an over-represention of the translational motion components in the spectral matrix, so that the dominant polarization direction that is extracted by an eigenanalysis would be widely insensitive to the rotational components. This is something we want to avoid, since the rotational components carry the phase velocity information that we are interested in. To give each component an equal weight in the analysis, we therefore convert the acceleration seismograms to rotation rates by the use of a scaling velocity (see Sollberger et al., 2018). This ensures that the amplitudes of all six time series are on the same order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_scal=4500 # We choose a scaling velocity of 4500 m/s to ensure that all components are on \n",
    "            # the same order of magnitude\n",
    "traN[0].data = traN[0].data / v_scal\n",
    "traE[0].data = traE[0].data / v_scal\n",
    "traZ[0].data = traZ[0].data / v_scal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to set up the 6DOF polarization analysis problem. The spectral matrices from which the polarization attributes are estimated are computed in a time-frequency window.  We choose the window to be frequency-dependent and extend over 1 period (1/f) in the time direction and over 0.01 Hz in the frequency direction: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = {'window_length_periods': 1, 'window_length_frequencies': 0.01}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up the polarization analysis, we will use the RotPol interface that is provided in the module pol6C. Here, we want to set up a problem to analyse Rayleigh waves, such as described in the accompanying paper. For this, we will need to pass the following data and parameters to the interface:\n",
    "- traN: translational North component\n",
    "- traE: translational East component\n",
    "- traZ: translational Z component\n",
    "- rotN: rotational North component\n",
    "- rotE: rotational East component\n",
    "- rotZ: rotational Z component\n",
    "- method: Defines how the polarization model is fitted to the data. Here we use an objective function ('DOT') that is based on the dot product between the model parameter vector and the dominat eigenvector of the spectral matrix, such as described in the accompanying paper. \n",
    "- search: 'grid' indicates that we are performing a simple grid search to find the best-fitting model parameters.\n",
    "- domain: 'f' specifies that we want to perform the analysis in the frequency domain on spectrograms.\n",
    "- spectrogram: 'st' chooses the S-transform as the method for spectrogram computation.\n",
    "- v_scal: To estimate phase velocities, the algorithm needs to know by what value the translational components were scaled.\n",
    "- free_surface: True specifies that our recording station is located at the Earth's surface where special conditions apply. This is the default setting. Use free_surface=False when analysing borehole data.\n",
    "\n",
    "Since we are trying to find our best-fitting model parameters by a grid search, we additionally need to specify the range of parameters that determine the model space that we want to explore. For a Rayleigh wave, there are three parameters determining the 6DOF polarization, namely the Rayleigh wave phase velocity (vr), the back-azimuth (phi) and the ellipticity angle (xi). \n",
    "\n",
    "- vr_range=[2000, 4000, 200] defines the range of Rayleigh wave phase velocities that are used in the optimization, ranging from 2000 m/s to 4000 m/s in a 200 m/s increment\n",
    "- phi_range=[-30, 10, 2] defines that we want to test back-azimuth values from -30 to 10 degrees in a 2 degree increment\n",
    "- xi_range=[-np.pi/4, np.pi/4, np.pi/46] defines the range of ellipticity angles that are tested in the optimization\n",
    "\n",
    "\n",
    "Scanning over a finer grid will lead to more accurate results, at the expense of increasing computational costs. In this tutorial, we use a rather coarse parametrization of the model space to keep the problem computationally tractable. For the same reason, we choose a rather narrow model space for the back-azimuth, expanding over 40Â° around the theoretical back-azimuth (-11 degrees) of the gulf of Alaska earthquake.\n",
    "\n",
    "Additionally, we limit the analysis to the frequency range where we expect the Rayleigh waves to be dominant (0.01 to 0.15 Hz) via:\n",
    "\n",
    "- frange=[0.01, 0.15] # Frequency range within which the analysis is performed\n",
    "\n",
    "To further decrease the computational demands, we will not perform the analysis at each time-frequency pair in the spectrogram but only at every 20th point in both the time and frequency directions:\n",
    "\n",
    "- dsfacf=20 # Downsampling factor in the frequency direction\n",
    "- dsfact=20 # Downsampling factor in the time direction\n",
    "\n",
    "To fully reproduce the results shown in the accompanying paper, please use the parameters given at the very bottom of this tutorial (note that due to the larger model space and wider frequency-range that is explored in the paper, this will require heavy computational resources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol = pr.RotPol(traN=traN, traE=traE, traZ=traZ, rotN=rotN, rotE=rotE, rotZ=rotZ, method=\"DOT\",\n",
    "                search='grid', domain='f', spectrogram='st', free_surface=True, phi_range=[-30, 10, 2], \n",
    "                vr_range=[2000, 4000, 200], xi_range=[-np.pi/4, np.pi/4, np.pi / 46], dsfacf=20, dsfact=20, \n",
    "                v_scal=v_scal, window=window, frange=[0.01, 0.15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is now being set up. This involves computing the S-transform of the 6DOF time series, computing the spectral matrices, averaging the spectral matrices within the time-frequency window, and down-sampling. To avoid an excessive use of memory, the spectral matrices are saved to a HDF5 on the disk.\n",
    "\n",
    "Alternatively, we could use a global optimization method to explore the parameter space by setting search='global'. In this case, a differential evolution algorithm will be used to find the set of best-fitting wave parameters (Storn & Price, 1997, https://doi.org/10.1023/A:1008202821328). This enables a more efficient exploration of large parameter spaces. Note that this comes at the risk of getting trapped in a local maximum if highly non-linear estimators such as the MUSIC algorithm (method=\"MUSIC\") are used. To apply the global optimization approach to the example in this tutorial, uncomment the code in the following cell. Note that this enables us to explore a much larger parameter space (phi_range=[-180, 180], xi_range=[-np.pi/2, np.pi/2]) and that there is no need to define a parameter space increment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pol = pr.RotPol(traN=traN, traE=traE, traZ=traZ, rotN=rotN, rotE=rotE, rotZ=rotZ, method=\"DOT\",\n",
    "#                search='global', domain='f', spectrogram='st', free_surface=True, phi_range=[-180, 180], vr_range=[2000, 4000],\n",
    "#                xi_range=[-np.pi/2, np.pi/2], dsfacf=20, dsfact=20, v_scal=v_scal, \n",
    "#                window=window, frange=[0.01, 0.15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these preparatory steps, we can now start the estimation of Rayleigh wave parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol.estimate_r() # Function to estimate Rayleigh wave parameters\n",
    "\n",
    "# Wave parameters for other wave types can be computed via:\n",
    "# pol.estimate_p() # For P-waves\n",
    "# pol.estimate_sv() # For SV-waves\n",
    "# pol.estimate_sh() # For SH-waves\n",
    "# pol.estimate_l() # For Love waves\n",
    "# Or:\n",
    "# pol.estimate_all() # Sequentially estimates wave parameters for all wave types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is now estimating Rayleigh wave parameters by fitting the six-component polarisation model of Rayleigh waves to the observed polarisation in the data by exploring the pre-defined model space. \n",
    "\n",
    "This will take a while (anywhere between 10 and 30 minutes, depending on the available computer power), so sit back while the computer is doing the work!\n",
    "\n",
    "Once the parameters are computed, you can save your analysis to the disk to make sure that you are not losing any results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol.save('Rayleigh_analysis.pkl') # This saves the analysis to the disc\n",
    "pol = pr.load('Rayleigh_analysis.pkl') # To read the analysis from a saved file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is a protocol to check whether wave parameters for a certain wave type are already computed in order to avoid double computations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol.estimate_r()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now inspect the results of our analysis. We can access the estimated wave parameters via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr = pol.get_vr() # Estimated Rayleigh wave phase velocities\n",
    "phi = pol.get_phi('R') # Estimated Rayleigh wave back-azimuth,  \n",
    "                       # 'R' specifies the wave type (Rayleigh wave)\n",
    "                      # for which the back-azimuth is retrieved\n",
    "xi = pol.get_xi() # Estimated Rayleigh ellipticity angle\n",
    "\n",
    "f = pol.f_pol # Frequency vector indicating where the parameters are computed\n",
    "t = pol.t_pol # Time vector indicating where the parameters are computed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we are interested in the likelihood values (between 0 and 1) that describe how well our best-fitting polarization model fits the data at a specific time-frequency pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lh = pol.get_lh('R') # Likelihood of the best-fitting polarisation model, \n",
    "                     # 'R' specifies that we want to retrieve the likelihood \n",
    "                     # for a Rayleigh wave polarization model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us inspect this likelihood as a function of time and frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traN_st, f = pr.s_transform(traN[0].data, dsfacf=20) #This computes the S-transform of the translational North component\n",
    "\n",
    "\n",
    "fig2, axes2 = plt.subplots(2, 1, sharex=True, figsize=(12, 4), dpi=100)\n",
    "\n",
    "plt21 = axes2[0].imshow(np.abs(traN_st), aspect='auto',  \n",
    "        extent=[date2num(pol.t_pol[0].datetime), date2num(pol.t_pol[-1].datetime), 0, 1 / pol.delta / 2],\n",
    "        origin='lower', cmap='viridis') # Plot the S-transform\n",
    "axes2[0].xaxis_date()\n",
    "fig2.autofmt_xdate()\n",
    "axes2[0].set_ylim(pol.frange)\n",
    "axes2[0].set_ylabel('Frequency (Hz)')\n",
    "axes2[0].set_title('S-transform of the translational North component')\n",
    "cbar21 = fig2.colorbar(plt21, ax=axes2[0], extend='max')\n",
    "cbar21.set_label(\"Amplitude\")\n",
    "\n",
    "\n",
    "plt22= axes2[1].imshow(lh, aspect='auto',  \n",
    "        extent=[date2num(pol.t_pol[0].datetime), date2num(pol.t_pol[-1].datetime), pol.f_pol[0], pol.f_pol[-1]],\n",
    "        origin='lower', cmap='inferno', vmin=0.7) # Plot the likelihood for a Rayleigh wave, clipped at 0.7\n",
    "axes2[1].xaxis_date()\n",
    "fig2.autofmt_xdate()\n",
    "axes2[1].set_ylim(pol.frange)\n",
    "axes2[1].set_ylabel('Frequency (Hz)')\n",
    "axes2[1].set_title('Likelihood')\n",
    "cbar22 = fig2.colorbar(plt22, ax=axes2[1], extend='max')\n",
    "cbar22.set_label(\"Likelihood\")\n",
    "plt.xlabel('Time (UTC)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that high likelihood values are only attained where the Rayleigh wave polarization model fits the data. The Rayleigh wave train is clearly visible arriving at about 10:10 UTC showing high likelihood values. This property can be used to automatically classify arrivals in the spectrogram in terms of their wave type. \n",
    "\n",
    "Note that the Rayleigh wave polarization model also seems to fit the data at random time-frequency pixels before the arrival of the Rayleigh wave train. This is likely due to noise, and can be suppressed using a conventional smoothing filter.\n",
    "\n",
    "Let us now inspect the extracted wave parameters (Fig. 4 in the accompanying paper):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors # Modules needed for plotting\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib.ticker as tck\n",
    "\n",
    "alpha = colors.Normalize(vmin=0.7)(lh) # We only want to display the results where a reasonable fit of the \n",
    "                                       # Rayleigh wave polarization model to the data was found (likelihood>0.7).\n",
    "                                       # To do so, we define an alpha channel that fades out all data point \n",
    "                                       # with a likelihood smaller than 0.7\n",
    "alpha[alpha < 0.] = 0.\n",
    "alpha[alpha > 1.] = 1.\n",
    "\n",
    "\n",
    "figs, axes = plt.subplots(4, 1, sharex=True, figsize=(16, 10))\n",
    "\n",
    "# Plot S-transform\n",
    "plot1 = axes[0].imshow(np.abs(traN_st), origin='lower', cmap='viridis', aspect='auto',\n",
    "                       extent=[date2num(pol.t_pol[0].datetime), date2num(pol.t_pol[-1].datetime), 0, 1/pol.delta/2])\n",
    "cbar0=figs.colorbar(plot1, ax=axes[0], extend='max')\n",
    "cbar0.set_label('Amplitude')\n",
    "axes[0].set_ylim(pol.frange)\n",
    "axes[0].set_title(\"S-transform of Vertical component\")\n",
    "axes[0].set_ylabel(\"Frequency (Hz)\")\n",
    "axes[0].xaxis_date()\n",
    "\n",
    "\n",
    "# Plot phase velocity\n",
    "plt1=axes[1].imshow(vr, alpha=alpha, extent=[date2num(pol.t_pol[0].datetime), date2num(pol.t_pol[-1].datetime), pol.f_pol[0], pol.f_pol[-1]], cmap='inferno', origin='lower',\n",
    "                    aspect='auto', vmin=3000, vmax=3800)\n",
    "axes[1].set_title(f\"Rayleigh-wave phase velocity\")\n",
    "axes[1].set_ylim(pol.frange)\n",
    "axes[1].xaxis_date()\n",
    "axes[1].set_ylabel(\"Frequency (Hz)\")\n",
    "\n",
    "\n",
    "\n",
    "map = ScalarMappable(colors.Normalize(vmin=3000, vmax=3800), cmap='inferno')\n",
    "cbar1 = figs.colorbar(map, ax=axes[1], extend='max')\n",
    "cbar1.set_label(f\"Phase velocity (m/s)\")\n",
    "\n",
    "# Plot back-azimuth\n",
    "plt2=axes[2].imshow(phi[:, :], alpha=alpha[:, :], extent=[date2num(pol.t_pol[0].datetime), date2num(pol.t_pol[-1].datetime), pol.f_pol[0], pol.f_pol[-1]], cmap='jet', origin='lower',\n",
    "                    aspect='auto', vmin=-180, vmax=180)\n",
    "axes[2].set_title(f\"Rayleigh-wave back-azimuth\")\n",
    "axes[2].set_ylim(pol.frange)\n",
    "axes[2].xaxis_date()\n",
    "axes[2].set_ylabel(\"Frequency (Hz)\")\n",
    "\n",
    "\n",
    "\n",
    "map = ScalarMappable(colors.Normalize(vmin=-180, vmax=180), cmap='jet')\n",
    "cbar2 = figs.colorbar(map, ax=axes[2], extend='max')\n",
    "cbar2.set_label(f\"Azimuth (degrees)\")\n",
    "\n",
    "# Plot ellipticity\n",
    "plt3=axes[3].imshow(xi[:, :], alpha=alpha[:, :], extent=[date2num(pol.t_pol[0].datetime), date2num(pol.t_pol[-1].datetime), pol.f_pol[0], pol.f_pol[-1]], cmap='jet', origin='lower',\n",
    "                    aspect='auto', vmin=-np.pi/4, vmax=np.pi/4)\n",
    "axes[3].set_title(f\"Rayleigh-wave ellipticity angle\")\n",
    "axes[3].set_ylim(pol.frange)\n",
    "axes[3].xaxis_date()\n",
    "axes[3].set_ylabel(\"Frequency (Hz)\")\n",
    "\n",
    "\n",
    "\n",
    "figs.autofmt_xdate()\n",
    "\n",
    "map = ScalarMappable(colors.Normalize(vmin=-np.pi/4/np.pi, vmax=np.pi/4/np.pi), cmap='jet')\n",
    "cbar3 = figs.colorbar(map, ax=axes[3], extend='max')\n",
    "cbar3.set_label(f\"Ellipticity angle (rad)\")\n",
    "cbar3.ax.yaxis.set_major_formatter(tck.FormatStrFormatter('%g $\\pi$'))\n",
    "cbar3.ax.yaxis.set_major_locator(tck.MultipleLocator(base=0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the dispersion characteristics that can be observed in the extracted phase velocities: events with high phase-velocities are observed arriving first at low frequencies, followed by events showing lower phase velocities at higher frequencies. \n",
    "\n",
    "In a next step, we want to use the likelihood values obtained above to filter the data, which allows us to separate certain wave types from the seismograms. Separated data can be extracted in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sep = pol.separate('R', vmin=0.7, vmax=0.8) # 'R' specifies that we want to separate a Rayleigh wave\n",
    "                                                 # vmin=0.7 specifies that we suppress all data in the \n",
    "                                                 # spectrogram where the Rayleigh wave polarization model \n",
    "                                                 # fits the data with a likelihood smaller than 0.7 (weight=0). \n",
    "                                                 # vmax=0.8 specifies that we fully retain all signal with\n",
    "                                                 # estimated likelihood values larger than 0.8 (weight=1).\n",
    "                                                 # Linear weights between 0 and 1 are given to data points \n",
    "                                                 # with likelihood values between 0.7 and 0.8.\n",
    "\n",
    "# data_sep is a list with six entries, containing separated data for each component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now look at the separated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, sharex=True, figsize=(16, 3))\n",
    "# For a fair comparison, we first filter the raw data to the frequency range, where we performed the analysis\n",
    "traN = pol.traN.filter('bandpass', freqmin=pol.frange[0], freqmax=pol.frange[1])\n",
    "ax[0].plot(pol.traN[0].data * v_scal, 'k')\n",
    "ax[1].plot(data_sep[0] * v_scal, 'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the high-frequency body wave phases are removed from the data, while the low-frequency Rayleigh waves remain in the separated data. \n",
    "\n",
    "In order to perform the separation, the estimated likelihood values need to be interpolated to the full resolution of the spectrogram. This step can result in interpolation artifacts. Using a finer sampling of the spectrograms in the analysis can help to reduce these artifacts.\n",
    "\n",
    "To exactly reproduce the processing as shown in the accompanying paper, please uncomment the following code (**Note that this will require heavy computational resources!**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pol_paper = pr.RotPol(traN=traN, traE=traE, traZ=traZ, rotN=rotN, rotE=rotE, rotZ=rotZ, method=\"DOT\",\n",
    "#                 search='grid', delta=1., domain='f', vp_range=[6000, 8500, 250],\n",
    "#                 vs_range=[2000, 4000, 200], theta_range=[0, 45, 1], phi_range=[-180, 180, 1], vr_range=[2000, 4000, 200],\n",
    "#                 xi_range=[-np.pi/4, np.pi / 4, np.pi / 91], vl_range=[2000, 4000, 200], v_scal=scal, dsfacf=10, dsfact=10)\n",
    "#pol_paper.estimate_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
